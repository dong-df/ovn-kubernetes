<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/ovn-kubernetes/assets/css/style.css?v=9e6c62f21184b23c5bdbecd995abe5f149115b0f" media="screen" type="text/css">
    <link rel="stylesheet" href="/ovn-kubernetes/assets/css/print.css" media="print" type="text/css">

    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>OVN kubernetes KIND Setup | OVN-Kubernetes Homepage</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="OVN kubernetes KIND Setup" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="test" />
<meta property="og:description" content="test" />
<link rel="canonical" href="http://www.ovn.org/ovn-kubernetes/kind.html" />
<meta property="og:url" content="http://www.ovn.org/ovn-kubernetes/kind.html" />
<meta property="og:site_name" content="OVN-Kubernetes Homepage" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="OVN kubernetes KIND Setup" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"test","headline":"OVN kubernetes KIND Setup","url":"http://www.ovn.org/ovn-kubernetes/kind.html"}</script>
<!-- End Jekyll SEO tag -->


    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/ovn-kubernetes/favicon.ico" -->

<!-- end custom head snippets -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="http://www.ovn.org/ovn-kubernetes/">
          <h1>OVN-Kubernetes Homepage</h1>
        </a>
        <h2>test</h2>
        
          <a href="https://github.com/ovn-org/ovn-kubernetes" class="button"><small>View project on</small> GitHub</a>
        
        
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1 id="ovn-kubernetes-kind-setup">OVN kubernetes KIND Setup</h1>

<p>KIND (Kubernetes in Docker) deployment of OVN kubernetes is a fast and easy means to quickly install and test kubernetes with OVN kubernetes CNI. The value proposition is really for developers who want to reproduce an issue or test a fix in an environment that can be brought up locally and within a few minutes.</p>

<h3 id="prerequisites">Prerequisites</h3>

<ul>
  <li>20 GB of free space in root file system</li>
  <li>Docker run time or podman</li>
  <li><a href="https://kubernetes.io/docs/setup/learning-environment/kind/">KIND</a>
    <ul>
      <li>Installation instructions can be found at https://github.com/kubernetes-sigs/kind#installation-and-usage.</li>
      <li>
        <p>NOTE: The OVN-Kubernetes <a href="https://github.com/ovn-org/ovn-kubernetes/blob/master/contrib/kind.sh">ovn-kubernetes/contrib/kind.sh</a> and <a href="https://github.com/ovn-org/ovn-kubernetes/blob/master/contrib/kind.yaml">ovn-kubernetes/contrib/kind.yaml</a> files provision port 11337. If firewalld is enabled, this port will need to be unblocked:</p>

        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> sudo firewall-cmd --permanent --add-port=11337/tcp; sudo firewall-cmd --reload
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">kubectl</a></li>
  <li>Python and pip</li>
  <li>jq</li>
</ul>

<p><strong>NOTE :</strong>  In certain operating systems such as CentOS 8.x, pip2 and pip3 binaries are installed instead of pip. In such situations create a softlink for “pip” that points to “pip2”.</p>

<h3 id="run-the-kind-deployment-with-docker">Run the KIND deployment with docker</h3>

<p>For OVN kubernetes KIND deployment, use the <code class="language-plaintext highlighter-rouge">kind.sh</code> script.</p>

<p>First Download and build the OVN-Kubernetes repo:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ go env -w GO111MODULE=auto
$ go get github.com/ovn-org/ovn-kubernetes; cd $(go env GOPATH)/src/github.com/ovn-org/ovn-kubernetes
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">kind.sh</code> script builds OVN-Kubernetes into a container image. To verify
local changes before building in KIND, run the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ pushd go-controller
$ make
$ popd

$ pushd dist/images
$ make fedora
$ popd
</code></pre></div></div>

<p>Launch the KIND Deployment.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ pushd contrib
$ export KUBECONFIG=${HOME}/ovn.conf
$ ./kind.sh
$ popd
</code></pre></div></div>

<p>This will launch a KIND deployment. By default the cluster is named <code class="language-plaintext highlighter-rouge">ovn</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get nodes
NAME                STATUS   ROLES    AGE     VERSION
ovn-control-plane   Ready    master   5h13m   v1.16.4
ovn-worker          Ready    &lt;none&gt;   5h12m   v1.16.4
ovn-worker2         Ready    &lt;none&gt;   5h12m   v1.16.4

$ kubectl get pods --all-namespaces
NAMESPACE            NAME                                        READY   STATUS    RESTARTS   AGE
kube-system          coredns-5644d7b6d9-kw2xc                    1/1     Running   0          5h13m
kube-system          coredns-5644d7b6d9-sd9wh                    1/1     Running   0          5h13m
kube-system          etcd-ovn-control-plane                      1/1     Running   0          5h11m
kube-system          kube-apiserver-ovn-control-plane            1/1     Running   0          5h12m
kube-system          kube-controller-manager-ovn-control-plane   1/1     Running   0          5h12m
kube-system          kube-scheduler-ovn-control-plane            1/1     Running   0          5h11m
local-path-storage   local-path-provisioner-7745554f7f-9r8dz     1/1     Running   0          5h13m
ovn-kubernetes       ovnkube-db-5588bd699c-kb8h7                 2/2     Running   0          5h11m
ovn-kubernetes       ovnkube-master-6f44d456df-bv2x8             2/2     Running   0          5h11m
ovn-kubernetes       ovnkube-node-2t6m2                          3/3     Running   0          5h11m
ovn-kubernetes       ovnkube-node-hhsmk                          3/3     Running   0          5h11m
ovn-kubernetes       ovnkube-node-xvqh4                          3/3     Running   0          5h11m
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">kind.sh</code> script defaults the cluster to HA disabled. There are numerous
configuration options when deploying. Use <code class="language-plaintext highlighter-rouge">./kind.sh -h</code> to see the latest options.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[root@ovnkubernetes contrib]# ./kind.sh --help
usage: kind.sh [[[-cf |--config-file &lt;file&gt;] [-kt|keep-taint] [-ha|--ha-enabled]
                 [-ho |--hybrid-enabled] [-ii|--install-ingress] [-n4|--no-ipv4]
                 [-i6 |--ipv6] [-wk|--num-workers &lt;num&gt;] [-ds|--disable-snat-multiple-gws]
                 [-dp |--disable-pkt-mtu-check] [-df|--disable-forwarding]
                 [-nf |--netflow-targets &lt;targets&gt;] [sf|--sflow-targets &lt;targets&gt;]
                 [-if |--ipfix-targets &lt;targets&gt;] [-ifs|--ipfix-sampling &lt;num&gt;]
                 [-ifm|--ipfix-cache-max-flows &lt;num&gt;] [-ifa|--ipfix-cache-active-timeout &lt;num&gt;]
                 [-sw |--allow-system-writes] [-gm|--gateway-mode &lt;mode&gt;]
                 [-nl |--node-loglevel &lt;num&gt;] [-ml|--master-loglevel &lt;num&gt;]
                 [-dbl|--dbchecker-loglevel &lt;num&gt;] [-ndl|--ovn-loglevel-northd &lt;loglevel&gt;]
                 [-nbl|--ovn-loglevel-nb &lt;loglevel&gt;] [-sbl|--ovn-loglevel-sb &lt;loglevel&gt;]
                 [-cl |--ovn-loglevel-controller &lt;loglevel&gt;] [-me|--multicast-enabled]
                 [-ep |--experimental-provider &lt;name&gt;] |
                 [-eb |--egress-gw-separate-bridge]
                 [-h]]

-cf  | --config-file                Name of the KIND J2 configuration file.
                                    DEFAULT: ./kind.yaml.j2
-kt  | --keep-taint                 Do not remove taint components.
                                    DEFAULT: Remove taint components.
-ha  | --ha-enabled                 Enable high availability. DEFAULT: HA Disabled.
-me  | --multicast-enabled          Enable multicast. DEFAULT: Disabled.
-scm | --separate-cluster-manager   Separate cluster manager from ovnkube-master and run as a separate container within ovnkube-master deployment.
-ho  | --hybrid-enabled             Enable hybrid overlay. DEFAULT: Disabled.
-ds  | --disable-snat-multiple-gws  Disable SNAT for multiple gws. DEFAULT: Disabled.
-dp  | --disable-pkt-mtu-check      Disable checking packet size greater than MTU. Default: Disabled
-df  | --disable-forwarding         Disable forwarding on OVNK controlled interfaces. Default: Enabled
-nf  | --netflow-targets            Comma delimited list of ip:port or :port (using node IP) netflow collectors. DEFAULT: Disabled.
-sf  | --sflow-targets              Comma delimited list of ip:port or :port (using node IP) sflow collectors. DEFAULT: Disabled.
-if  | --ipfix-targets              Comma delimited list of ip:port or :port (using node IP) ipfix collectors. DEFAULT: Disabled.
-ifs | --ipfix-sampling             Fraction of packets that are sampled and sent to each target collector: 1 packet out of every &lt;num&gt;. DEFAULT: 400 (1 out of 400 packets).
-ifm | --ipfix-cache-max-flows      Maximum number of IPFIX flow records that can be cached at a time. If 0, caching is disabled. DEFAULT: Disabled.
-ifa | --ipfix-cache-active-timeout Maximum period in seconds for which an IPFIX flow record is cached and aggregated before being sent. If 0, caching is disabled. DEFAULT: 60.
-el  | --ovn-empty-lb-events        Enable empty-lb-events generation for LB without backends. DEFAULT: Disabled
-ii  | --install-ingress            Flag to install Ingress Components.
                                    DEFAULT: Don't install ingress components.
-n4  | --no-ipv4                    Disable IPv4. DEFAULT: IPv4 Enabled.
-i6  | --ipv6                       Enable IPv6. DEFAULT: IPv6 Disabled.
-wk  | --num-workers                Number of worker nodes. DEFAULT: HA - 2 worker
                                    nodes and no HA - 0 worker nodes.
-sw  | --allow-system-writes        Allow script to update system. Intended to allow
                                    github CI to be updated with IPv6 settings.
                                    DEFAULT: Don't allow.
-gm  | --gateway-mode               Enable 'shared' or 'local' gateway mode.
                                    DEFAULT: shared.
-ov  | --ovn-image            	    Use the specified docker image instead of building locally. DEFAULT: local build.
-ml  | --master-loglevel            Log level for ovnkube (master), DEFAULT: 5.
-nl  | --node-loglevel              Log level for ovnkube (node), DEFAULT: 5
-dbl | --dbchecker-loglevel         Log level for ovn-dbchecker (ovnkube-db), DEFAULT: 5.
-ndl | --ovn-loglevel-northd        Log config for ovn northd, DEFAULT: '-vconsole:info -vfile:info'.
-nbl | --ovn-loglevel-nb            Log config for northbound DB DEFAULT: '-vconsole:info -vfile:info'.
-sbl | --ovn-loglevel-sb            Log config for southboudn DB DEFAULT: '-vconsole:info -vfile:info'.
-cl  | --ovn-loglevel-controller    Log config for ovn-controller DEFAULT: '-vconsole:info'.
-ep  | --experimental-provider      Use an experimental OCI provider such as podman, instead of docker. DEFAULT: Disabled.
-eb  | --egress-gw-separate-bridge  The external gateway traffic uses a separate bridge.
-lr  |--local-kind-registry         Will start and connect a kind local registry to push/retrieve images
--delete                      	    Delete current cluster
--deploy                      	    Deploy ovn kubernetes without restarting kind
</code></pre></div></div>

<p>As seen above, if you do not specify any options the script will assume the default values.</p>

<h3 id="run-the-kind-deployment-with-podman">Run the KIND deployment with podman</h3>

<p>To verify local changes, the steps are mostly the same as with docker, except the <code class="language-plaintext highlighter-rouge">fedora</code> make target:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ OCI_BIN=podman make fedora
</code></pre></div></div>

<p>To deploy KIND however, you need to start it as root and then copy root’s kube config to use it as non-root:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ pushd contrib
$ sudo ./kind.sh -ep podman
$ sudo cp /root/ovn.conf ~/.kube/kind-config
$ sudo chown $(id -u):$(id -g) ~/.kube/kind-config
$ export KUBECONFIG=~/.kube/kind-config
$ popd
</code></pre></div></div>

<p><strong>Notes / troubleshooting:</strong></p>

<ul>
  <li>Issue with /dev/dma_heap: if you get the error <code class="language-plaintext highlighter-rouge">kind "Error: open /dev/dma_heap: permission denied"</code>, there’s a <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1966158">known issue</a> about it (directory mislabelled with selinux).
Workaround:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>setenforce 0
<span class="nb">sudo chcon </span>system<span class="se">\_</span>u:object<span class="se">\_</span>r:device<span class="se">\_</span>t:s0 /dev/dma<span class="se">\_</span>heap/
<span class="nb">sudo </span>setenforce 1
</code></pre></div></div>

<ul>
  <li>If you see errors related to go, you may not have go <code class="language-plaintext highlighter-rouge">$PATH</code> configured as root. Make sure it is configured, or define it while running <code class="language-plaintext highlighter-rouge">kind.sh</code>:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:/usr/local/go/bin ./kind.sh <span class="nt">-ep</span> podman
</code></pre></div></div>

<h3 id="usage-notes">Usage Notes</h3>

<ul>
  <li>
    <p>You can create your own KIND J2 configuration file if the default one is not sufficient</p>
  </li>
  <li>
    <p>You can also specify these values as environment variables. Command line parameters will override the environment variables.</p>
  </li>
  <li>
    <p>To tear down the KIND cluster when finished simply run</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> $ ./kind.sh --delete
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="running-ovn-kubernetes-with-ipv6-or-dual-stack-in-kind">Running OVN-Kubernetes with IPv6 or Dual-stack In KIND</h2>

<p>This section describes the configuration needed for IPv6 and dual-stack environments.</p>

<h2 id="kind-with-ipv6">KIND with IPv6</h2>

<h3 id="docker-changes-for-ipv6">Docker Changes For IPv6</h3>

<p>For KIND clusters using KIND v0.7.0 or older (CI currently is using v0.8.1), to
use IPv6, IPv6 needs to be enable in Docker on the host:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo vi /etc/docker/daemon.json
{
  "ipv6": true
}

$ sudo systemctl reload docker
</code></pre></div></div>

<p>On a CentOS host running Docker version 19.03.6, the above configuration worked.
After the host was rebooted, Docker failed to start. To fix, change
<code class="language-plaintext highlighter-rouge">daemon.json</code> as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo vi /etc/docker/daemon.json
{
  "ipv6": true,
  "fixed-cidr-v6": "2001:db8:1::/64"
}

$ sudo systemctl reload docker
</code></pre></div></div>

<p><a href="https://github.com/docker/docker.github.io/blob/c0eb65aabe4de94d56bbc20249179f626df5e8c3/engine/userguide/networking/default_network/ipv6.md">IPv6</a>
from Docker repo provided the fix. Newer documentation does not include this
change, so change may be dependent on Docker version.</p>

<p>To verify IPv6 is enabled in Docker, run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker run --rm busybox ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
341: eth0@if342: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 2001:db8:1::242:ac11:2/64 scope global flags 02
       valid_lft forever preferred_lft forever
    inet6 fe80::42:acff:fe11:2/64 scope link tentative
       valid_lft forever preferred_lft forever
</code></pre></div></div>

<p>For the eth0 vEth-pair, there should be the two IPv6 entries (global and link
addresses).</p>

<h3 id="disable-firewalld">Disable firewalld</h3>

<p>Currently, to run OVN-Kubernetes with IPv6 only in a KIND deployment, firewalld
needs to be disabled. To disable:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo systemctl stop firewalld
</code></pre></div></div>

<p>NOTE: To run with IPv4, firewalld needs to be enabled, so to reenable:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo systemctl start firewalld
</code></pre></div></div>

<p>If firewalld is enabled during a IPv6 deployment, additional nodes fail to join
the cluster:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>:
Creating cluster "ovn" ...
 ✓ Ensuring node image (kindest/node:v1.18.2) 🖼
 ✓ Preparing nodes 📦 📦 📦
 ✓ Writing configuration 📜
 ✓ Starting control-plane 🕹️
 ✓ Installing StorageClass 💾
 ✗ Joining worker nodes 🚜
ERROR: failed to create cluster: failed to join node with kubeadm: command "docker exec --privileged ovn-worker kubeadm join --config /kind/kubeadm.conf --ignore-preflight-errors=all --v=6" failed with error: exit status 1
</code></pre></div></div>

<p>And logs show:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>I0430 16:40:44.590181     579 token.go:215] [discovery] Failed to request cluster-info, will try again: Get https://[2001:db8:1::242:ac11:3]:6443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s: dial tcp [2001:db8:1::242:ac11:3]:6443: connect: permission denied
Get https://[2001:db8:1::242:ac11:3]:6443/api/v1/namespaces/kube-public/configmaps/cluster-info?timeout=10s: dial tcp [2001:db8:1::242:ac11:3]:6443: connect: permission denied
</code></pre></div></div>

<p>This issue was reported upstream in KIND
<a href="https://github.com/kubernetes-sigs/kind/issues/1257#issuecomment-575984987">1257</a>
and blamed on firewalld.</p>

<h3 id="ovn-kubernetes-with-ipv6">OVN-Kubernetes With IPv6</h3>

<p>To run OVN-Kubernetes with IPv6 in a KIND deployment, run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ go get github.com/ovn-org/ovn-kubernetes; cd $GOPATH/src/github.com/ovn-org/ovn-kubernetes

$ cd go-controller/
$ make

$ cd ../dist/images/
$ make fedora

$ cd ../../contrib/
$ KIND_IPV4_SUPPORT=false KIND_IPV6_SUPPORT=true ./kind.sh
</code></pre></div></div>

<p>Once <code class="language-plaintext highlighter-rouge">kind.sh</code> completes, setup kube config file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cp ~/ovn.conf ~/.kube/config
-- OR --
$ KUBECONFIG=~/ovn.conf
</code></pre></div></div>

<p>Once testing is complete, to tear down the KIND deployment:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kind delete cluster --name ovn
</code></pre></div></div>

<h2 id="kind-with-dual-stack">KIND with Dual-stack</h2>

<p>Currently, IP dual-stack is not fully supported in:</p>
<ul>
  <li>Kubernetes</li>
  <li>KIND</li>
  <li>OVN-Kubernetes</li>
</ul>

<h3 id="kubernetes-and-docker-with-ip-dual-stack">Kubernetes And Docker With IP Dual-stack</h3>

<h4 id="update-kubectl">Update kubectl</h4>

<p>Kubernetes has some IP dual-stack support but the feature is not complete.
Additional changes are constantly being added. This setup is using the latest
Kubernetes release to test against. Kubernetes is being installed below using
OVN-Kubernetes KIND script, however to test, an equivalent version of <code class="language-plaintext highlighter-rouge">kubectl</code>
needs to be installed.</p>

<p>First determine what version of <code class="language-plaintext highlighter-rouge">kubectl</code> is currently being used and save it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ which kubectl
/usr/bin/kubectl
$ kubectl version --client
Client Version: version.Info{Major:"1", Minor:"28", GitVersion:"v1.17.3", GitCommit:"06ad960bfd03b39c8310aaf92d1e7c12ce618213", GitTreeState:"clean", BuildDate:"2020-02-11T18:14:22Z", GoVersion:"go1.13.6", Compiler:"gc", Platform:"linux/amd64"}
sudo mv /usr/bin/kubectl /usr/bin/kubectl-v1.17.3
sudo ln -s /usr/bin/kubectl-v1.17.3 /usr/bin/kubectl
</code></pre></div></div>

<p>Download and install latest version of <code class="language-plaintext highlighter-rouge">kubectl</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ K8S_VERSION=v1.29.2
$ curl -LO https://storage.googleapis.com/kubernetes-release/release/$K8S_VERSION/bin/linux/amd64/kubectl
$ chmod +x kubectl
$ sudo mv kubectl /usr/bin/kubectl-$K8S_VERSION
$ sudo rm /usr/bin/kubectl
$ sudo ln -s /usr/bin/kubectl-$K8S_VERSION /usr/bin/kubectl
$ kubectl version --client
Client Version: version.Info{Major:"1", Minor:"28", GitVersion:"v1.18.0", GitCommit:"9e991415386e4cf155a24b1da15becaa390438d8", GitTreeState:"clean", BuildDate:"2020-03-25T14:58:59Z", GoVersion:"go1.13.8", Compiler:"gc", Platform:"linux/amd64"}
</code></pre></div></div>

<h3 id="docker-changes-for-dual-stack">Docker Changes For Dual-stack</h3>

<p>For dual-stack, IPv6 needs to be enable in Docker on the host same as
for IPv6 only. See above: <a href="#docker-changes-for-ipv6">Docker Changes For IPv6</a></p>

<h3 id="kind-with-ip-dual-stack">KIND With IP Dual-stack</h3>

<p>IP dual-stack is not currently supported in KIND. There is a PR
(<a href="https://github.com/kubernetes-sigs/kind/pull/692">692</a>)
with IP dual-stack changes. Currently using this to test with.</p>

<p>Optionally, save previous version of KIND (if it exists):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cp $GOPATH/bin/kind $GOPATH/bin/kind.orig
</code></pre></div></div>

<h4 id="build-kind-with-dual-stack-locally">Build KIND With Dual-stack Locally</h4>

<p>To build locally (if additional needed):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>go get github.com/kubernetes-sigs/kind; cd $GOPATH/src/github.com/kubernetes-sigs/kind
git pull --no-edit --strategy=ours origin pull/692/head
make clean
make install INSTALL_DIR=$GOPATH/bin
</code></pre></div></div>

<h3 id="ovn-kubernetes-with-ip-dual-stack">OVN-Kubernetes With IP Dual-stack</h3>

<p>For status of IP dual-stack in OVN-Kubernetes, see
<a href="https://github.com/ovn-org/ovn-kubernetes/issues/1142">1142</a>.</p>

<p>To run OVN-Kubernetes with IP dual-stack in a KIND deployment, run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ go get github.com/ovn-org/ovn-kubernetes; cd $GOPATH/src/github.com/ovn-org/ovn-kubernetes

$ cd go-controller/
$ make

$ cd ../dist/images/
$ make fedora

$ cd ../../contrib/
$ KIND_IPV4_SUPPORT=true KIND_IPV6_SUPPORT=true K8S_VERSION=v1.29.2 ./kind.sh
</code></pre></div></div>

<p>Once <code class="language-plaintext highlighter-rouge">kind.sh</code> completes, setup kube config file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cp ~/ovn.conf ~/.kube/config
-- OR --
$ KUBECONFIG=~/ovn.conf
</code></pre></div></div>

<p>Once testing is complete, to tear down the KIND deployment:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kind delete cluster --name ovn
</code></pre></div></div>

<h3 id="using-specific-kind-container-image-and-tag">Using specific Kind container image and tag</h3>

<p>:warning: Use with caution, as kind expects this image to have all it needs.</p>

<p>In order to use an image/tag other than the default hardcoded in kind.sh, specify
one (or both of) the following variables:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cd ../../contrib/
$ KIND_IMAGE=example.com/kindest/node K8S_VERSION=v1.29.2 ./kind.sh
</code></pre></div></div>

<h3 id="using-kind-local-registry-to-deploy-non-ovn-k-containers">Using kind local registry to deploy non ovn-k containers</h3>

<p>A local registry can be made available to the cluster if started with:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./kind.sh --local-kind-registry
</code></pre></div></div>
<p>This is useful if you want to make your own local images available to the 
cluster. These images can be pushed, fetched or used 
in manifests using the prefix <code class="language-plaintext highlighter-rouge">localhost:5000</code>.</p>

<h3 id="loading-ovn-kubernetes-changes-without-restarting-kind">Loading ovn-kubernetes changes without restarting kind</h3>

<p>Sometimes it is useful to update ovn-kubernetes without redeploying the whole 
cluster all over again. For example, when testing the update itself. 
This can be achieve with the “–deploy” flag:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Default options will use kind mechanism to push images directly to the</span>
./kind.sh <span class="nt">--deploy</span>

<span class="c"># Using a local registry is an alternative to deploy ovn-kubernetes updates </span>
<span class="c"># while also being useful to deploy other local images</span>
./kind.sh <span class="nt">--deploy</span> <span class="nt">--local-kind-registry</span>
</code></pre></div></div>

<h3 id="current-status">Current Status</h3>

<p>This is subject to change because code is being updated constantly. But this is
more a cautionary note that this feature is not completely working at the
moment.</p>

<p>The nodes do not go to ready because the OVN-Kubernetes hasn’t setup the network
completely:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get nodes
NAME                STATUS     ROLES    AGE   VERSION
ovn-control-plane   NotReady   master   94s   v1.18.0
ovn-worker          NotReady   &lt;none&gt;   61s   v1.18.0
ovn-worker2         NotReady   &lt;none&gt;   62s   v1.18.0

$ kubectl get pods -o wide --all-namespaces
NAMESPACE          NAME                                      READY STATUS   RESTARTS AGE    IP          NODE
kube-system        coredns-66bff467f8-hh4c9                  0/1   Pending  0        2m45s  &lt;none&gt;      &lt;none&gt;
kube-system        coredns-66bff467f8-vwbcj                  0/1   Pending  0        2m45s  &lt;none&gt;      &lt;none&gt;
kube-system        etcd-ovn-control-plane                    1/1   Running  0        2m56s  172.17.0.2  ovn-control-plane
kube-system        kube-apiserver-ovn-control-plane          1/1   Running  0        2m56s  172.17.0.2  ovn-control-plane
kube-system        kube-controller-manager-ovn-control-plane 1/1   Running  0        2m56s  172.17.0.2  ovn-control-plane
kube-system        kube-scheduler-ovn-control-plane          1/1   Running  0        2m56s  172.17.0.2  ovn-control-plane
local-path-storage local-path-provisioner-774f7f8fdb-msmd2   0/1   Pending  0        2m45s  &lt;none&gt;      &lt;none&gt;
ovn-kubernetes     ovnkube-db-cf4cc89b7-8d4xq                2/2   Running  0        107s   172.17.0.2  ovn-control-plane
ovn-kubernetes     ovnkube-master-87fb56d6d-7qmnb            2/2   Running  0        107s   172.17.0.2  ovn-control-plane
ovn-kubernetes     ovnkube-node-278l9                        2/3   Running  0        107s   172.17.0.3  ovn-worker2
ovn-kubernetes     ovnkube-node-bm7v6                        2/3   Running  0        107s   172.17.0.2  ovn-control-plane
ovn-kubernetes     ovnkube-node-p4k4t                        2/3   Running  0        107s   172.17.0.4  ovn-worker
</code></pre></div></div>

<h3 id="known-issues">Known issues</h3>

<p>Some environments (Fedora32,31 on desktop), have problems when the cluster
is deleted directly with kind <code class="language-plaintext highlighter-rouge">kind delete cluster --name ovn</code>, it restarts the host.
The root cause is unknown, this also can not be reproduced in Ubuntu 20.04 or
with Fedora32 Cloud, but it does not happen if we clean first the ovn-kubernetes resources.</p>

<p>You can use the following command to delete the cluster:</p>

<p><code class="language-plaintext highlighter-rouge">contrib/kind.sh --delete</code></p>

        </section>

        <aside id="sidebar">
          

          
            <p class="repo-owner"><a href="https://github.com/ovn-org/ovn-kubernetes">ovn-kubernetes</a> is maintained by <a href="https://github.com/ovn-org">ovn-org</a>.</p>
          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</p>
        </aside>
      </div>
    </div>

  </body>
</html>
