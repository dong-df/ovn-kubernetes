<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/ovn-kubernetes/assets/css/style.css?v=9e6c62f21184b23c5bdbecd995abe5f149115b0f" media="screen" type="text/css">
    <link rel="stylesheet" href="/ovn-kubernetes/assets/css/print.css" media="print" type="text/css">

    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Live Migration | OVN-Kubernetes Homepage</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Live Migration" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="test" />
<meta property="og:description" content="test" />
<link rel="canonical" href="http://www.ovn.org/ovn-kubernetes/live-migration.html" />
<meta property="og:url" content="http://www.ovn.org/ovn-kubernetes/live-migration.html" />
<meta property="og:site_name" content="OVN-Kubernetes Homepage" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Live Migration" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"test","headline":"Live Migration","url":"http://www.ovn.org/ovn-kubernetes/live-migration.html"}</script>
<!-- End Jekyll SEO tag -->


    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/ovn-kubernetes/favicon.ico" -->

<!-- end custom head snippets -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="http://www.ovn.org/ovn-kubernetes/">
          <h1>OVN-Kubernetes Homepage</h1>
        </a>
        <h2>test</h2>
        
          <a href="https://github.com/ovn-org/ovn-kubernetes" class="button"><small>View project on</small> GitHub</a>
        
        
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1 id="live-migration">Live Migration</h1>

<h2 id="introduction">Introduction</h2>

<p>The Live Migration feature allows <a href="kubevirt.io">kubevirt</a> virtual machines to be <a href="https://kubevirt.io/user-guide/operations/live_migration/">live migrated</a>
while keeping the established TCP connections alive, and preserving the VM IP configuration.
These two requirements provide seamless live-migration of a KubeVirt VM using OVN-Kubernetes
cluster default network.</p>

<h2 id="requirements">Requirements</h2>

<ul>
  <li>KubeVirt &gt;= v1.0.0</li>
  <li>DHCP aware guest image (fedora family is well tested, https://quay.io/organization/containerdisks)</li>
</ul>

<h1 id="limitations">Limitations</h1>

<ul>
  <li>Only KubeVirt VMs with bridge binding pod network are supported</li>
  <li>Single stack IPv6 is not supported</li>
  <li>DualSack does not configure routes for IPv6 over DHCP/autoconf</li>
  <li>SRIOV is not supported</li>
</ul>

<h2 id="example-live-migrating-a-fedora-guest-image">Example: live migrating a fedora guest image</h2>

<p>Install KubeVirt following the guide <a href="https://kubevirt.io/user-guide/operations/installation/">here</a></p>

<p>Create a fedora virtual machine with the annotations <code class="language-plaintext highlighter-rouge">kubevirt.io/allow-pod-bridge-network-live-migration</code>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">'</span><span class="no">EOF</span><span class="sh">' | kubectl create -f -
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  name: fedora
spec:
  runStrategy: Always
  template:
    metadata:
      annotations:
        # Allow KubeVirt VMs with bridge binding to be migratable
        # also ovn-k will not configure network at pod, delegate it to DHCP
        kubevirt.io/allow-pod-bridge-network-live-migration: ""
    spec:
      domain:
        devices:
          disks:
          - disk:
              bus: virtio
            name: containerdisk
          - disk:
              bus: virtio
            name: cloudinit
          rng: {}
        features:
          acpi: {}
          smm:
            enabled: true
        firmware:
          bootloader:
            efi:
              secureBoot: true
        resources:
          requests:
            memory: 1Gi
      terminationGracePeriodSeconds: 180
      volumes:
      - containerDisk:
          image: quay.io/containerdisks/fedora:38
        name: containerdisk
      - cloudInitNoCloud:
          networkData: |
            version: 2
            ethernets:
              eth0:
                dhcp4: true
          userData: |-
            #cloud-config
            # The default username is: fedora
            password: fedora
            chpasswd: { expire: False }
        name: cloudinit
</span><span class="no">EOF
</span></code></pre></div></div>

<p>After waiting for the VM to be ready - <code class="language-plaintext highlighter-rouge">kubectl wait vmi fedora --for=condition=Ready --timeout=5m</code> -
the VM status should be as shown below - i.e. <code class="language-plaintext highlighter-rouge">kubectl get vmi fedora</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get vmi fedora
NAME     AGE     PHASE     IP            NODENAME      READY
fedora   9m42s   Running   10.244.2.26   ovn-worker3   True
</code></pre></div></div>

<p>Login and check that the VM has receive a proper address <code class="language-plaintext highlighter-rouge">virtctl console fedora</code></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>fedora@fedora ~]ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    <span class="nb">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1400 qdisc fq_codel state UP group default qlen 1000
    <span class="nb">link</span>/ether 0a:58:0a:f4:02:1a brd ff:ff:ff:ff:ff:ff
    altname enp1s0
    inet 10.244.2.26/24 brd 10.244.2.255 scope global dynamic noprefixroute eth0
       valid_lft 3412sec preferred_lft 3412sec
    inet6 fe80::32d2:10d4:f5ed:3064/64 scope <span class="nb">link </span>noprefixroute
       valid_lft forever preferred_lft forever
</code></pre></div></div>

<p>Also we can check the neighbours cache to verify it later on</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>fedora@fedora ~]arp <span class="nt">-a</span>
_gateway <span class="o">(</span>169.254.1.1<span class="o">)</span> at 0a:58:a9:fe:01:01 <span class="o">[</span>ether] on eth0
</code></pre></div></div>

<p>Keep in mind the default gw is a link local address; that is because 
the live migration feature is implemented using ARP proxy.</p>

<p>The last route is needed since the link local address subnet is not bound to any interface, that
route is automatically created by dhcp client.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>fedora@fedora ~]ip route
default via 169.254.1.1 dev eth0 proto dhcp src 10.244.2.26 metric 100
10.244.2.0/24 dev eth0 proto kernel scope <span class="nb">link </span>src 10.244.2.26 metric 100
169.254.1.1 dev eth0 proto dhcp scope <span class="nb">link </span>src 10.244.2.26 metric 100
</code></pre></div></div>

<p>Then a live migration can be initialized with <code class="language-plaintext highlighter-rouge">virtctl migrate fedora</code> and wait
at the vmim resource</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>virtctl migrate fedora
VM fedora was scheduled to migrate
kubectl get vmim <span class="nt">-A</span> <span class="nt">-o</span> yaml
  status:
    migrationState:
      completed: <span class="nb">true</span>
</code></pre></div></div>

<p>After migration, the network configuration is the same - including the GW neighbor cache.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>oc get vmi <span class="nt">-A</span>
NAMESPACE   NAME     AGE   PHASE     IP            NODENAME     READY
default     fedora   16m   Running   10.244.2.26   ovn-worker   True
<span class="o">[</span>fedora@fedora ~]ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    <span class="nb">link</span>/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1400 qdisc fq_codel state UP group default qlen 1000
    <span class="nb">link</span>/ether 0a:58:0a:f4:02:1a brd ff:ff:ff:ff:ff:ff
    altname enp1s0
    inet 10.244.2.26/24 brd 10.244.2.255 scope global dynamic noprefixroute eth0
       valid_lft 2397sec preferred_lft 2397sec
    inet6 fe80::32d2:10d4:f5ed:3064/64 scope <span class="nb">link </span>noprefixroute
       valid_lft forever preferred_lft forever
<span class="o">[</span>fedora@fedora ~]arp <span class="nt">-a</span>
_gateway <span class="o">(</span>169.254.1.1<span class="o">)</span> at 0a:58:a9:fe:01:01 <span class="o">[</span>ether] on eth0
</code></pre></div></div>

<h1 id="configuring-dns-server">Configuring dns server</h1>
<p>By default the DHCP server at ovn-kuberntes will configure the kubernetes
default dns service <code class="language-plaintext highlighter-rouge">kube-system/kube-dns</code> as the name server. This can be
overriden with the following command line options:</p>
<ul>
  <li>dns-service-namespace</li>
  <li>dns-service-name</li>
</ul>

<h1 id="configuring-dual-stack-guest-images">Configuring dual stack guest images</h1>
<p>For dual stack, ovn-kubernetes is configuring the IPv6 address to guest VMs using
DHCPv6, but the IPv6 default gateway has to be configured manually.
Since this address is the same - <code class="language-plaintext highlighter-rouge">fe80::1</code> - the virtual machine configuration
is stable.</p>

<p>Both the ipv4 and ipv6 configurations have to be activated.</p>

<p>NOTE: The IPv6 autoconf/SLAAC is not supported at ovn-k live-migration</p>

<p>For fedora cloud-init can be used to activate dual stack:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="pi">-</span> <span class="na">cloudInitNoCloud</span><span class="pi">:</span>
     <span class="na">networkData</span><span class="pi">:</span> <span class="pi">|</span>
       <span class="s">version: 2</span>
       <span class="s">ethernets:</span>
         <span class="s">eth0:</span>
           <span class="s">dhcp4: true</span>
           <span class="s">dhcp6: true</span>
     <span class="na">userData</span><span class="pi">:</span> <span class="pi">|-</span>
       <span class="s">#cloud-config</span>
       <span class="s"># The default username is: fedora</span>
       <span class="s">password: fedora</span>
       <span class="s">chpasswd: { expire: False }</span>
       <span class="s">runcmd:</span>
         <span class="s">- nmcli c m "cloud-init eth0" ipv6.method dhcp</span>
         <span class="s">- nmcli c m "cloud-init eth0" +ipv6.routes "fe80::1"</span>
         <span class="s">- nmcli c m "cloud-init eth0" +ipv6.routes "::/0 fe80::1"</span>
         <span class="s">- nmcli c reload "cloud-init eth0"</span>
</code></pre></div></div>

<p>For fedora coreos this can be configured with using the following
ignition yaml:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">variant</span><span class="pi">:</span> <span class="s">fcos</span>
<span class="na">version</span><span class="pi">:</span> <span class="s">1.4.0</span>
<span class="na">storage</span><span class="pi">:</span>
  <span class="na">files</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/etc/nmstate/001-dual-stack-dhcp.yml</span>
      <span class="na">contents</span><span class="pi">:</span>
        <span class="na">inline</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">interfaces:</span>
          <span class="s">- name: enp1s0</span>
            <span class="s">type: ethernet</span>
            <span class="s">state: up</span>
            <span class="s">ipv4:</span>
              <span class="s">enabled: true</span>
              <span class="s">dhcp: true</span>
            <span class="s">ipv6:</span>
              <span class="s">enabled: true</span>
              <span class="s">dhcp: true</span>
              <span class="s">autoconf: false</span>
    <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/etc/nmstate/002-dual-sack-ipv6-gw.yml</span>
      <span class="na">contents</span><span class="pi">:</span>
        <span class="na">inline</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">routes:</span>
            <span class="s">config:</span>
            <span class="s">- destination: ::/0</span>
              <span class="s">next-hop-interface: enp1s0</span>
              <span class="s">next-hop-address: fe80::1</span>
</code></pre></div></div>

        </section>

        <aside id="sidebar">
          

          
            <p class="repo-owner"><a href="https://github.com/ovn-org/ovn-kubernetes">ovn-kubernetes</a> is maintained by <a href="https://github.com/ovn-org">ovn-org</a>.</p>
          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</p>
        </aside>
      </div>
    </div>

  </body>
</html>
